{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Tutorial: reddit_ideology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -e ..\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Package & config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(\"..\"))    # from scripts/ up to css_package/\n",
    "SRC_PATH     = os.path.join(PROJECT_ROOT, \"src\")      # â€¦/css_package/src\n",
    "print(\"Adding to sys.path:\", SRC_PATH)\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "print(\"sys.path now contains:\")\n",
    "for p in sys.path[:5]:\n",
    "    print(\"  \", p)\n",
    "\n",
    "from reddit_ideology import (\n",
    "    load_config,\n",
    "    DataLoader,\n",
    "    Preprocessor,\n",
    "    EmbeddingModel,\n",
    "    TopicModel,\n",
    "    MetricsCalculator,\n",
    "    Visualizer\n",
    ")\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    config['data']['conservative_path'],\n",
    "    config['data']['liberal_path']\n",
    ")\n",
    "cons_df, lib_df = dl.load()\n",
    "\n",
    "cons_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preprocessor()\n",
    "cons_df = pp.apply(cons_df)\n",
    "lib_df = pp.apply(lib_df)\n",
    "\n",
    "cons_df[['text','clean_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_cfg = config['embedding']\n",
    "embedder = EmbeddingModel(\n",
    "    model_name=emb_cfg['model_name'],\n",
    "    batch_size=emb_cfg['batch_size'],\n",
    "    device=emb_cfg['device'],\n",
    "    cache_dir=config['output']['cache_dir']\n",
    ")\n",
    "cons_emb = embedder.embed(cons_df['clean_text'].tolist(), name=\"conservative\")\n",
    "lib_emb = embedder.embed(lib_df['clean_text'].tolist(), name=\"liberal\")\n",
    "\n",
    "print(\"Shapes:\", cons_emb.shape, lib_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Topic Modeling via Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_cfg = config['topic_model']['cluster']\n",
    "topic_model = TopicModel(\n",
    "    umap_neighbors=tm_cfg['umap_neighbors'],\n",
    "    umap_min_dist=tm_cfg['umap_min_dist'],\n",
    "    hdbscan_min_cluster_size=tm_cfg['hdbscan_min_cluster_size'],\n",
    "    cache_dir=config['output']['cache_dir']\n",
    ")\n",
    "cons_topics = topic_model.fit(cons_emb, name=\"conservative\")\n",
    "lib_topics = topic_model.fit(lib_emb, name=\"liberal\")\n",
    "\n",
    "print(\"Conservative topics:\", np.unique(cons_topics))\n",
    "print(\"Liberal topics:\", np.unique(lib_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from reddit_ideology.openai_utils import init_openai, generate_topic_label\n",
    "from reddit_ideology.topic_model import EmbeddingClusterTopicModel\n",
    "from reddit_ideology.metrics import MetricsCalculator\n",
    "\n",
    "client = init_openai(config['openai']['api_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) Extract top terms & label topics ===\n",
    "def extract_top_terms(df, topics, top_n):\n",
    "    counts = {}\n",
    "    for tid in sorted(set(topics)):\n",
    "        texts = df.loc[topics == tid, 'clean_text']\n",
    "        words = Counter(\" \".join(texts).split())\n",
    "        counts[tid] = [w for w,_ in words.most_common(top_n)]\n",
    "    return counts\n",
    "\n",
    "max_terms = config.get('openai', {}).get('max_terms', 10)\n",
    "# conservative\n",
    "cons_terms  = extract_top_terms(cons_df, cons_topics, max_terms)\n",
    "cons_labels = {\n",
    "    tid: generate_topic_label(client, terms, model=config['openai']['model'])\n",
    "    for tid, terms in cons_terms.items()\n",
    "}\n",
    "# liberal\n",
    "lib_terms  = extract_top_terms(lib_df, lib_topics, max_terms)\n",
    "lib_labels = {\n",
    "    tid: generate_topic_label(client, terms, model=config['openai']['model'])\n",
    "    for tid, terms in lib_terms.items()\n",
    "}\n",
    "\n",
    "# === 3) Compute all metrics ===\n",
    "mc = MetricsCalculator(config['output']['metrics_dir'])\n",
    "\n",
    "cons_metrics = mc.topic_entropy_and_count(\n",
    "    topics=cons_topics,\n",
    "    timestamps=cons_df['timestamp'],\n",
    "    freq=config['analysis']['time_interval']\n",
    ")\n",
    "lib_metrics = mc.topic_entropy_and_count(\n",
    "    topics=lib_topics,\n",
    "    timestamps=lib_df['timestamp'],\n",
    "    freq=config['analysis']['time_interval']\n",
    ")\n",
    "\n",
    "spread_df = mc.semantic_spread(\n",
    "    embeddings=np.vstack([cons_emb, lib_emb]),\n",
    "    topics=np.concatenate([cons_topics, lib_topics]),\n",
    "    timestamps=pd.concat([cons_df['timestamp'], lib_df['timestamp']]),\n",
    "    freq=config['analysis']['time_interval']\n",
    ")\n",
    "\n",
    "intra_cons = mc.intra_group_similarity(\n",
    "    embeddings=cons_emb,\n",
    "    timestamps=cons_df['timestamp'],\n",
    "    freq=config['analysis']['time_interval']\n",
    ")\n",
    "intra_lib = mc.intra_group_similarity(\n",
    "    embeddings=lib_emb,\n",
    "    timestamps=lib_df['timestamp'],\n",
    "    freq=config['analysis']['time_interval']\n",
    ")\n",
    "cross_sim = mc.cross_group_similarity(\n",
    "    emb1=cons_emb, emb2=lib_emb,\n",
    "    ts1=cons_df['timestamp'], ts2=lib_df['timestamp'],\n",
    "    freq=config['analysis']['time_interval']\n",
    ")\n",
    "\n",
    "# === 4) Quick check ===\n",
    "print(\"Conservative topic labels:\", cons_labels)\n",
    "print(\"Liberal topic labels:     \", lib_labels)\n",
    "cons_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from IPython.display import Image, display\n",
    "from reddit_ideology.config import load_config\n",
    "from reddit_ideology.visualize import Visualizer\n",
    "\n",
    "# Load config & parse events\n",
    "cfg = load_config('config.yaml')\n",
    "outdir = cfg['output']['plots_dir']\n",
    "prepost = cfg.get('stats', {}).get('prepost_window', 3)\n",
    "events = [{'name': ev['name'], 'date': pd.to_datetime(ev['date'])} for ev in cfg.get('events', [])]\n",
    "\n",
    "# Statistical tests & p-values\n",
    "years_con = cons_metrics['period'].dt.year.astype(int)\n",
    "p_ent_con = stats.linregress(years_con, cons_metrics['entropy']).pvalue\n",
    "years_lib = lib_metrics['period'].dt.year.astype(int)\n",
    "p_ent_lib = stats.linregress(years_lib, lib_metrics['entropy']).pvalue\n",
    "print(f\"Q1: Entropy trend p-values => conservative={p_ent_con:.3g}, liberal={p_ent_lib:.3g}\")\n",
    "\n",
    "for ev in events:\n",
    "    before = cross_sim[\n",
    "        (cross_sim['period'] >= ev['date'] - pd.DateOffset(months=prepost)) &\n",
    "        (cross_sim['period'] < ev['date'])\n",
    "    ]['cross_similarity']\n",
    "    after = cross_sim[\n",
    "        (cross_sim['period'] > ev['date']) &\n",
    "        (cross_sim['period'] <= ev['date'] + pd.DateOffset(months=prepost))\n",
    "    ]['cross_similarity']\n",
    "    if len(before) and len(after):\n",
    "        p = stats.ttest_ind(before, after, equal_var=False).pvalue\n",
    "        print(f\"Q2 ({ev['name']}): cross-sim p-value = {p:.3g}\")\n",
    "\n",
    "merged = pd.merge(\n",
    "    intra_cons.rename(columns={'intra_similarity':'con'}),\n",
    "    intra_lib.rename(columns={'intra_similarity':'lib'}),\n",
    "    on='period'\n",
    ")\n",
    "p_echo = stats.ttest_rel(merged['con'], merged['lib']).pvalue\n",
    "print(f\"Q3: Intra-group similarity difference p-value = {p_echo:.3g}\")\n",
    "\n",
    "# Visualizations\n",
    "viz = Visualizer(outdir)\n",
    "viz.plot_time_series(cons_metrics, 'period', 'entropy', title='Conservative Entropy', filename='cons_entropy.png')\n",
    "viz.plot_time_series(lib_metrics, 'period', 'entropy', title='Liberal Entropy', filename='lib_entropy.png')\n",
    "viz.plot_time_series(cons_metrics, 'period', 'topic_count', title='Conservative Topic Count', filename='cons_topic_count.png')\n",
    "viz.plot_time_series(lib_metrics, 'period', 'topic_count', title='Liberal Topic Count', filename='lib_topic_count.png')\n",
    "\n",
    "ribbon = spread_df.groupby('period')['spread'].agg(\n",
    "    median='median',\n",
    "    q1=lambda x: x.quantile(0.25),\n",
    "    q3=lambda x: x.quantile(0.75)\n",
    ").reset_index()\n",
    "viz.plot_ribbon(ribbon, 'period', 'median', 'q1', 'q3', title='Semantic Spread', filename='semantic_spread.png')\n",
    "\n",
    "viz.plot_time_series(cross_sim, 'period', 'cross_similarity', title='Cross-Community Similarity', events=events, filename='cross_similarity.png')\n",
    "viz.plot_time_series(intra_cons, 'period', 'intra_similarity', title='Conservative Echo Chamber', filename='intra_cons.png')\n",
    "viz.plot_time_series(intra_lib, 'period', 'intra_similarity', title='Liberal Echo Chamber', filename='intra_lib.png')\n",
    "\n",
    "def freq_df(df, topics):\n",
    "    return (\n",
    "        pd.DataFrame({'timestamp': df['timestamp'], 'topic': topics})\n",
    "        .assign(\n",
    "            period=lambda d: d['timestamp']\n",
    "                               .dt.to_period(cfg['analysis']['time_interval'])\n",
    "                               .dt.to_timestamp()\n",
    "        )\n",
    "        .groupby(['period','topic'])\n",
    "        .size()\n",
    "        .reset_index(name='count')\n",
    "    )\n",
    "\n",
    "cons_freq = freq_df(cons_df, cons_topics)\n",
    "lib_freq = freq_df(lib_df, lib_topics)\n",
    "cons_freq['topic_label'] = cons_freq['topic'].map(cons_labels)\n",
    "lib_freq['topic_label'] = lib_freq['topic'].map(lib_labels)\n",
    "\n",
    "top_n = cfg.get('analysis', {}).get('top_n', 5)\n",
    "viz.plot_topic_prevalence(cons_freq, period_col='period', topic_col='topic_label', count_col='count',\n",
    "                          top_n=top_n, normalize=True,\n",
    "                          title=f'Top {top_n} Conservative Topics Over Time',\n",
    "                          filename=f'cons_top{top_n}_topics.png')\n",
    "viz.plot_topic_prevalence(lib_freq, period_col='period', topic_col='topic_label', count_col='count',\n",
    "                          top_n=top_n, normalize=True,\n",
    "                          title=f'Top {top_n} Liberal Topics Over Time',\n",
    "                          filename=f'lib_top{top_n}_topics.png')\n",
    "viz.plot_combined_topic_trends(cons_freq, lib_freq, period_col='period', topic_col='topic_label',\n",
    "                               count_col='count', top_n=top_n, normalize=True,\n",
    "                               title=f'Top {top_n} Topics: Conservative vs Liberal',\n",
    "                               filename=f'combined_top{top_n}_topics.png')\n",
    "\n",
    "# Display all PNGs\n",
    "for fn in [\n",
    "    'cons_entropy.png', 'lib_entropy.png',\n",
    "    'cons_topic_count.png', 'lib_topic_count.png',\n",
    "    'semantic_spread.png', 'cross_similarity.png',\n",
    "    'intra_cons.png', 'intra_lib.png',\n",
    "    f'cons_top{top_n}_topics.png',\n",
    "    f'lib_top{top_n}_topics.png',\n",
    "    f'combined_top{top_n}_topics.png'\n",
    "]:\n",
    "    display(Image(f\"{outdir}/{fn}\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red_id",
   "language": "python",
   "name": "red_id"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
