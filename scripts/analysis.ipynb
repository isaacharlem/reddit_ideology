{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Tutorial: reddit_ideology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e ..\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Package & config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\n",
    "    os.path.join(\"..\")\n",
    ")  # from scripts/ up to css_package/\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")  # â€¦/css_package/src\n",
    "print(\"Adding to sys.path:\", SRC_PATH)\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "print(\"sys.path now contains:\")\n",
    "for p in sys.path[:5]:\n",
    "    print(\"  \", p)\n",
    "\n",
    "from reddit_ideology import (\n",
    "    load_config,\n",
    "    DataLoader,\n",
    "    Preprocessor,\n",
    "    EmbeddingModel,\n",
    "    TopicModel,\n",
    "    MetricsCalculator,\n",
    "    Visualizer,\n",
    ")\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    config[\"data\"][\"conservative_path\"], config[\"data\"][\"liberal_path\"]\n",
    ")\n",
    "cons_df, lib_df = dl.load()\n",
    "\n",
    "cons_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preprocessor()\n",
    "cons_df = pp.apply(cons_df)\n",
    "lib_df = pp.apply(lib_df)\n",
    "\n",
    "cons_df[[\"text\", \"clean_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_cfg = config[\"embedding\"]\n",
    "embedder = EmbeddingModel(\n",
    "    model_name=emb_cfg[\"model_name\"],\n",
    "    batch_size=emb_cfg[\"batch_size\"],\n",
    "    device=emb_cfg[\"device\"],\n",
    "    cache_dir=config[\"output\"][\"cache_dir\"],\n",
    ")\n",
    "cons_emb = embedder.embed(cons_df[\"clean_text\"].tolist(), name=\"conservative\")\n",
    "lib_emb = embedder.embed(lib_df[\"clean_text\"].tolist(), name=\"liberal\")\n",
    "\n",
    "print(\"Shapes:\", cons_emb.shape, lib_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Topic Modeling via Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_cfg = config[\"topic_model\"][\"cluster\"]\n",
    "topic_model = TopicModel(\n",
    "    umap_neighbors=tm_cfg[\"umap_neighbors\"],\n",
    "    umap_min_dist=tm_cfg[\"umap_min_dist\"],\n",
    "    hdbscan_min_cluster_size=tm_cfg[\"hdbscan_min_cluster_size\"],\n",
    "    cache_dir=config[\"output\"][\"cache_dir\"],\n",
    ")\n",
    "cons_topics = topic_model.fit(cons_emb, name=\"conservative\")\n",
    "lib_topics = topic_model.fit(lib_emb, name=\"liberal\")\n",
    "\n",
    "print(\"Conservative topics:\", np.unique(cons_topics))\n",
    "print(\"Liberal topics:\", np.unique(lib_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from reddit_ideology.openai_utils import init_openai, generate_topic_label\n",
    "from reddit_ideology.topic_model import EmbeddingClusterTopicModel\n",
    "from reddit_ideology.metrics import MetricsCalculator\n",
    "\n",
    "client = init_openai(config[\"openai\"][\"api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) Extract top terms & label topics ===\n",
    "def extract_top_terms(df, topics, top_n):\n",
    "    counts = {}\n",
    "    for tid in sorted(set(topics)):\n",
    "        texts = df.loc[topics == tid, \"clean_text\"]\n",
    "        words = Counter(\" \".join(texts).split())\n",
    "        counts[tid] = [w for w, _ in words.most_common(top_n)]\n",
    "    return counts\n",
    "\n",
    "\n",
    "max_terms = config.get(\"openai\", {}).get(\"max_terms\", 10)\n",
    "# conservative\n",
    "cons_terms = extract_top_terms(cons_df, cons_topics, max_terms)\n",
    "cons_labels = {\n",
    "    tid: generate_topic_label(client, terms, model=config[\"openai\"][\"model\"])\n",
    "    for tid, terms in cons_terms.items()\n",
    "}\n",
    "# liberal\n",
    "lib_terms = extract_top_terms(lib_df, lib_topics, max_terms)\n",
    "lib_labels = {\n",
    "    tid: generate_topic_label(client, terms, model=config[\"openai\"][\"model\"])\n",
    "    for tid, terms in lib_terms.items()\n",
    "}\n",
    "\n",
    "# === 3) Compute all metrics ===\n",
    "mc = MetricsCalculator(config[\"output\"][\"metrics_dir\"])\n",
    "\n",
    "cons_metrics = mc.topic_entropy_and_count(\n",
    "    topics=cons_topics,\n",
    "    timestamps=cons_df[\"timestamp\"],\n",
    "    freq=config[\"analysis\"][\"time_interval\"],\n",
    ")\n",
    "lib_metrics = mc.topic_entropy_and_count(\n",
    "    topics=lib_topics,\n",
    "    timestamps=lib_df[\"timestamp\"],\n",
    "    freq=config[\"analysis\"][\"time_interval\"],\n",
    ")\n",
    "\n",
    "spread_df = mc.semantic_spread(\n",
    "    embeddings=np.vstack([cons_emb, lib_emb]),\n",
    "    topics=np.concatenate([cons_topics, lib_topics]),\n",
    "    timestamps=pd.concat([cons_df[\"timestamp\"], lib_df[\"timestamp\"]]),\n",
    "    freq=config[\"analysis\"][\"time_interval\"],\n",
    ")\n",
    "\n",
    "intra_cons = mc.intra_group_similarity(\n",
    "    embeddings=cons_emb,\n",
    "    timestamps=cons_df[\"timestamp\"],\n",
    "    freq=config[\"analysis\"][\"time_interval\"],\n",
    ")\n",
    "intra_lib = mc.intra_group_similarity(\n",
    "    embeddings=lib_emb,\n",
    "    timestamps=lib_df[\"timestamp\"],\n",
    "    freq=config[\"analysis\"][\"time_interval\"],\n",
    ")\n",
    "cross_sim = mc.cross_group_similarity(\n",
    "    emb1=cons_emb,\n",
    "    emb2=lib_emb,\n",
    "    ts1=cons_df[\"timestamp\"],\n",
    "    ts2=lib_df[\"timestamp\"],\n",
    "    freq=config[\"analysis\"][\"time_interval\"],\n",
    ")\n",
    "\n",
    "# === 4) Quick check ===\n",
    "print(\"Conservative topic labels:\", cons_labels)\n",
    "print(\"Liberal topic labels:     \", lib_labels)\n",
    "cons_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from IPython.display import Image, display\n",
    "from reddit_ideology.config import load_config\n",
    "from reddit_ideology.visualize import Visualizer\n",
    "\n",
    "# Load config & parse events\n",
    "cfg = load_config(\"config.yaml\")\n",
    "outdir = cfg[\"output\"][\"plots_dir\"]\n",
    "prepost = cfg.get(\"stats\", {}).get(\"prepost_window\", 3)\n",
    "events = [\n",
    "    {\"name\": ev[\"name\"], \"date\": pd.to_datetime(ev[\"date\"])}\n",
    "    for ev in cfg.get(\"events\", [])\n",
    "]\n",
    "\n",
    "# Statistical tests & p-values\n",
    "years_con = cons_metrics[\"period\"].dt.year.astype(int)\n",
    "p_ent_con = stats.linregress(years_con, cons_metrics[\"entropy\"]).pvalue\n",
    "years_lib = lib_metrics[\"period\"].dt.year.astype(int)\n",
    "p_ent_lib = stats.linregress(years_lib, lib_metrics[\"entropy\"]).pvalue\n",
    "print(\n",
    "    f\"Q1: Entropy trend p-values => conservative={p_ent_con:.3g}, liberal={p_ent_lib:.3g}\"\n",
    ")\n",
    "\n",
    "for ev in events:\n",
    "    before = cross_sim[\n",
    "        (cross_sim[\"period\"] >= ev[\"date\"] - pd.DateOffset(months=prepost))\n",
    "        & (cross_sim[\"period\"] < ev[\"date\"])\n",
    "    ][\"cross_similarity\"]\n",
    "    after = cross_sim[\n",
    "        (cross_sim[\"period\"] > ev[\"date\"])\n",
    "        & (cross_sim[\"period\"] <= ev[\"date\"] + pd.DateOffset(months=prepost))\n",
    "    ][\"cross_similarity\"]\n",
    "    if len(before) and len(after):\n",
    "        p = stats.ttest_ind(before, after, equal_var=False).pvalue\n",
    "        print(f\"Q2 ({ev['name']}): cross-sim p-value = {p:.3g}\")\n",
    "\n",
    "merged = pd.merge(\n",
    "    intra_cons.rename(columns={\"intra_similarity\": \"con\"}),\n",
    "    intra_lib.rename(columns={\"intra_similarity\": \"lib\"}),\n",
    "    on=\"period\",\n",
    ")\n",
    "\n",
    "def freq_df(df, topics):\n",
    "    return (\n",
    "        pd.DataFrame({\"timestamp\": df[\"timestamp\"], \"topic\": topics})\n",
    "        .assign(\n",
    "            period=lambda d: d[\"timestamp\"]\n",
    "            .dt.to_period(cfg[\"analysis\"][\"time_interval\"])\n",
    "            .dt.to_timestamp()\n",
    "        )\n",
    "        .groupby([\"period\", \"topic\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "\n",
    "\n",
    "cons_freq = freq_df(cons_df, cons_topics)\n",
    "lib_freq = freq_df(lib_df, lib_topics)\n",
    "cons_freq[\"topic_label\"] = cons_freq[\"topic\"].map(cons_labels)\n",
    "lib_freq[\"topic_label\"] = lib_freq[\"topic\"].map(lib_labels)\n",
    "\n",
    "top_n = cfg.get(\"analysis\", {}).get(\"top_n\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "viz = Visualizer(outdir)\n",
    "viz.plot_time_series(\n",
    "    cons_metrics,\n",
    "    \"period\",\n",
    "    \"entropy\",\n",
    "    title=\"Conservative Entropy\",\n",
    "    filename=\"cons_entropy.png\",\n",
    ")\n",
    "viz.plot_time_series(\n",
    "    lib_metrics,\n",
    "    \"period\",\n",
    "    \"entropy\",\n",
    "    title=\"Liberal Entropy\",\n",
    "    filename=\"lib_entropy.png\",\n",
    ")\n",
    "viz.plot_time_series(\n",
    "    cons_metrics,\n",
    "    \"period\",\n",
    "    \"topic_count\",\n",
    "    title=\"Conservative Topic Count\",\n",
    "    filename=\"cons_topic_count.png\",\n",
    ")\n",
    "viz.plot_time_series(\n",
    "    lib_metrics,\n",
    "    \"period\",\n",
    "    \"topic_count\",\n",
    "    title=\"Liberal Topic Count\",\n",
    "    filename=\"lib_topic_count.png\",\n",
    ")\n",
    "\n",
    "ribbon = (\n",
    "    spread_df.groupby(\"period\")[\"spread\"]\n",
    "    .agg(\n",
    "        median=\"median\",\n",
    "        q1=lambda x: x.quantile(0.25),\n",
    "        q3=lambda x: x.quantile(0.75),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "viz.plot_ribbon(\n",
    "    ribbon,\n",
    "    \"period\",\n",
    "    \"median\",\n",
    "    \"q1\",\n",
    "    \"q3\",\n",
    "    title=\"Semantic Spread\",\n",
    "    filename=\"semantic_spread.png\",\n",
    ")\n",
    "\n",
    "viz.plot_time_series(\n",
    "    cross_sim,\n",
    "    \"period\",\n",
    "    \"cross_similarity\",\n",
    "    title=\"Cross-Community Similarity\",\n",
    "    events=events,\n",
    "    filename=\"cross_similarity.png\",\n",
    ")\n",
    "viz.plot_time_series(\n",
    "    intra_cons,\n",
    "    \"period\",\n",
    "    \"intra_similarity\",\n",
    "    title=\"Conservative Echo Chamber\",\n",
    "    filename=\"intra_cons.png\",\n",
    ")\n",
    "viz.plot_time_series(\n",
    "    intra_lib,\n",
    "    \"period\",\n",
    "    \"intra_similarity\",\n",
    "    title=\"Liberal Echo Chamber\",\n",
    "    filename=\"intra_lib.png\",\n",
    ")\n",
    "\n",
    "viz.plot_topic_prevalence(\n",
    "    cons_freq,\n",
    "    period_col=\"period\",\n",
    "    topic_col=\"topic_label\",\n",
    "    count_col=\"count\",\n",
    "    top_n=top_n,\n",
    "    normalize=True,\n",
    "    title=f\"Top {top_n} Conservative Topics Over Time\",\n",
    "    filename=f\"cons_top{top_n}_topics.png\",\n",
    ")\n",
    "viz.plot_topic_prevalence(\n",
    "    lib_freq,\n",
    "    period_col=\"period\",\n",
    "    topic_col=\"topic_label\",\n",
    "    count_col=\"count\",\n",
    "    top_n=top_n,\n",
    "    normalize=True,\n",
    "    title=f\"Top {top_n} Liberal Topics Over Time\",\n",
    "    filename=f\"lib_top{top_n}_topics.png\",\n",
    ")\n",
    "viz.plot_combined_topic_trends(\n",
    "    cons_freq,\n",
    "    lib_freq,\n",
    "    period_col=\"period\",\n",
    "    topic_col=\"topic_label\",\n",
    "    count_col=\"count\",\n",
    "    top_n=top_n,\n",
    "    normalize=True,\n",
    "    title=f\"Top {top_n} Topics: Conservative vs Liberal\",\n",
    "    filename=f\"combined_top{top_n}_topics.png\",\n",
    ")\n",
    "\n",
    "# Display all PNGs\n",
    "for fn in [\n",
    "    \"cons_entropy.png\",\n",
    "    \"lib_entropy.png\",\n",
    "    \"cons_topic_count.png\",\n",
    "    \"lib_topic_count.png\",\n",
    "    \"semantic_spread.png\",\n",
    "    \"cross_similarity.png\",\n",
    "    \"intra_cons.png\",\n",
    "    \"intra_lib.png\",\n",
    "    f\"cons_top{top_n}_topics.png\",\n",
    "    f\"lib_top{top_n}_topics.png\",\n",
    "    f\"combined_top{top_n}_topics.png\",\n",
    "]:\n",
    "    display(Image(f\"{outdir}/{fn}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red_id",
   "language": "python",
   "name": "red_id"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
